# Modular PDF Processor API

A clean, modular FastAPI server for PDF processing with Document AI, DLP masking, RAG enhancement, Knowledge Graph construction, and test case generation.

## ğŸ—ï¸ Project Structure

```
vertex_agent/
â”œâ”€â”€ api_server_modular.py          # Main API server
â”œâ”€â”€ modules/                       # Modular components
â”‚   â”œâ”€â”€ document_ai.py            # PDF text extraction
â”‚   â”œâ”€â”€ dlp_masking.py            # PII detection and masking
â”‚   â”œâ”€â”€ rag_enhancement.py        # RAG corpus queries
â”‚   â”œâ”€â”€ knowledge_graph.py        # KG construction and analysis
â”‚   â”œâ”€â”€ test_generation.py        # AI-powered test case generation
â”‚   â””â”€â”€ mock_data_loader.py       # Mock data loading utilities
â”œâ”€â”€ mockData/                      # Mock data directory
â”‚   â”œâ”€â”€ documents/                # Sample PDF files
â”‚   â”œâ”€â”€ responses/                # Mock API responses
â”‚   â”œâ”€â”€ inputs/                   # Sample input data
â”‚   â””â”€â”€ configs/                  # Mock configuration files
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ Dockerfile                   # Container configuration
â””â”€â”€ venv/                          # Virtual environment
```

## ğŸš€ Quick Start

1. **Activate virtual environment:**
   ```bash
   source venv/bin/activate
   ```

2. **Start the server:**
   ```bash
   python api_server_modular.py
   ```

3. **Test the API:**
   ```bash
   curl -X POST "http://localhost:8080/generate-ui-tests?gdpr_mode=true" \
        -F "file=@documents/PRD-3.pdf" \
        -H "Content-Type: multipart/form-data"
   ```

## ğŸ“¡ API Endpoints

- `GET /` - API information
- `GET /health` - Health check
- `POST /extract-document` - Document AI extraction only (PDF â†’ structured text + entities)
- `POST /extract-mask` - Document AI + DLP masking (PDF â†’ extraction + PII masking)
- `POST /rag-enhance` - Document AI + DLP + RAG enhancement (PDF â†’ extraction + PII masking + RAG corpus)
- `POST /build-knowledge-graph` - Document AI + DLP + RAG + KG construction (PDF â†’ knowledge graph with nodes & edges)
- `POST /generate-ui-tests` - Complete pipeline (Document AI â†’ DLP â†’ RAG â†’ KG â†’ Test Generation)

### Extract Document (Document AI Only)

Extract text and entities from a PDF using Google Cloud Document AI:

```bash
curl -X POST "http://localhost:8080/extract-document?use_mock=false" \
     -F "file=@mockData/documents/PRD-3.pdf" \
     -H "Content-Type: multipart/form-data"
```

### Extract + Mask (Document AI + DLP)

Extract text and automatically mask PII in one step:

```bash
curl -X POST "http://localhost:8080/extract-mask?gdpr_mode=true" \
     -F "file=@mockData/documents/PRD-3.pdf" \
     -H "Content-Type: multipart/form-data"
```

**Optimizations:**
- âœ… **Unified chunks**: Each chunk contains both `original_text` and `masked_text`
- âœ… **Non-blocking DLP**: Uses `asyncio.to_thread()` to prevent API blocking
- âœ… **Per-chunk edges**: `edges` array in each chunk for page-specific traceability
- âœ… **No duplication**: Single source of truth for `filename`, `mock_mode`, `gdpr_mode` (in `document`)
- âœ… **Flatter structure**: Per-chunk PII stats only (no global `total_pii_found` or `pii_types_detected`)
- âœ… **Smaller JSON**: Removed redundant fields, fully traceable from chunk-level data

### RAG Enhancement (Document AI + DLP + RAG)

Extract text, mask PII, and enhance with RAG corpus for compliance insights:

```bash
curl -X POST "http://localhost:8080/rag-enhance?gdpr_mode=true&rag_location=europe-west3" \
     -F "file=@mockData/documents/PRD-3.pdf" \
     -H "Content-Type: multipart/form-data"
```

**Parameters:**
- `rag_corpus_name` (str): Custom RAG corpus name (optional)
- `rag_location` (str): RAG corpus location (default: "europe-west3")

**Features:**
- âœ… **Async RAG Processing**: Concurrent chunk processing with `asyncio.gather()`
- âœ… **Dynamic Thresholding**: Intelligent similarity thresholds based on chunk length
- âœ… **Fuzzy Fallback**: Advanced fallback matching with `difflib.SequenceMatcher`
- âœ… **Policy Deduplication**: Smart deduplication of matched policies per chunk
- âœ… **Error Resilience**: Continues processing even if RAG corpus fails


### Build Knowledge Graph (Document AI + DLP + RAG + KG)

Extract text, mask PII, enhance with RAG, and build a comprehensive knowledge graph:

```bash
curl -X POST "http://localhost:8080/build-knowledge-graph?gdpr_mode=true&rag_location=europe-west3" \
     -F "file=@mockData/documents/PRD-3.pdf" \
     -H "Content-Type: multipart/form-data"
```

**Parameters:**
- `gdpr_mode` (bool): Enable PII masking with DLP (default: true)
- `rag_corpus_name` (str): Custom RAG corpus name (optional)
- `rag_location` (str): RAG corpus location (default: "europe-west3")
- `use_mock` (bool): Use mock data for testing (default: false)

**Features:**
- âœ… **Complete Pipeline**: Document AI â†’ DLP â†’ RAG â†’ Knowledge Graph
- âœ… **Compliance Normalization**: Canonical IDs for compliance standards (GDPR:2016/679, CCPA:2018, etc.)
- âœ… **Dual Node Creation**: Creates compliance nodes from both `detected_compliance` and `relationships[]`
- âœ… **Comprehensive Metadata**: Graph density, avg confidence, compliance by type, top connected nodes
- âœ… **Direct Relationship Consumption**: Uses optimized `relationships[]` from chunks

**Use cases:**
- Visualize compliance traceability in graph databases (Neo4j, Memgraph)
- Analyze requirement coverage and gaps
- Export to graph visualization tools (Cytoscape, Gephi)
- Generate compliance reports with full traceability

### Generate UI Tests (Full Pipeline)

Run the complete compliance traceability pipeline:

```bash
curl -X POST "http://localhost:8080/generate-ui-tests?gdpr_mode=true" \
     -F "file=@mockData/documents/PRD-3.pdf" \
     -H "Content-Type: multipart/form-data"
```

## ğŸ”§ Environment Variables

Set these environment variables for production:

- `PROJECT_ID` - **Google Cloud project ID (STRING, not project number!)**
  - âœ… Example: `"poc-genai-hacks"` or `"my-project-123"`
  - âŒ NOT the numeric project number like `"401328495550"`
  - ğŸ” Find it: Go to [Google Cloud Console](https://console.cloud.google.com) â†’ Project dropdown â†’ "ID" column
- `LOCATION` - Document AI processor location (default: "us")
- `PROCESSOR_ID` - Document AI processor ID
- `RAG_CORPUS_NAME` - RAG corpus name
- `RAG_LOCATION` - RAG corpus location
- `GEMINI_LOCATION` - Gemini model location
- `USE_MOCK_DOCAI` - Set to "true" to use mock Document AI data (default: "false")

## ğŸ”§ Document AI Setup

To use the actual Document AI API:

1. **Enable Document AI API** in your Google Cloud project
2. **Create a Document AI processor** in the Google Cloud Console
3. **Set environment variables:**
   ```bash
   # âš ï¸ IMPORTANT: Use PROJECT ID (string), NOT project number (numeric)
   export PROJECT_ID="poc-genai-hacks"  # Your project ID (string like "my-project")
   export LOCATION="us"  # Processor location
   export PROCESSOR_ID="e7f52140009fdda2"  # Your processor ID
   ```

4. **Document AI Endpoint:**
   ```
   # Note: Document AI endpoints can use project number OR project ID
   https://us-documentai.googleapis.com/v1/projects/poc-genai-hacks/locations/us/processors/e7f52140009fdda2:process

   # However, DLP API REQUIRES project ID (string), NOT project number
   ```

5. **For testing with mock data:**
   ```bash
   # Use mock data for testing
   curl -X POST "http://localhost:8080/extract-document?use_mock=true" \
        -F "file=@mockData/documents/PRD-3.pdf"
   ```


**âœ… Correct (Project ID):**
```bash
export PROJECT_ID="poc-genai-hacks"  # This is a project ID
```

## ğŸ“š API Documentation

Visit `http://localhost:8080/docs` for interactive API documentation.
